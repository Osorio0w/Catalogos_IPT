"""
leer_catalogo_v1_3_8_full.py
Versión 1.3.8 (completa) — Detección visual de imágenes + asociación a códigos
Requisitos:
    pip install pdfplumber opencv-python numpy pillow
Uso:
    python leer_catalogo_v1_3_8_full.py
"""
import os
import re
import math
import cv2
import numpy as np
import pdfplumber
from PIL import Image, ImageOps, ImageFont, ImageDraw

# --------------------------
# CONFIG (ajusta según tu catálogo)
# --------------------------
PDF_FILE = "PAPELERÍA.pdf"
OUTPUT_DIR = "images"
DEBUG_DIR = "debug_images"
DPI = 150

# reglas de detección de regiones (puedes afinar)
MIN_AREA = 8000           # px^2 mínimo para un recorte candidato
MAX_AREA = 300000         # px^2 máximo (evitar capturar página entera)
ASPECT_RATIO_RANGE = (0.4, 3.0)  # ancho/alto esperado (fotos variadas)
EDGE_THRESHOLD_LOW = 50
EDGE_THRESHOLD_HIGH = 150

# asociación imagen -> código
ASSOC_MAX_DY = 250        # px vertical máximo entre centro de imagen y centro de código
ASSOC_MAX_DX = 200        # px horizontal máximo

# output
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(DEBUG_DIR, exist_ok=True)

# --------------------------
# UTILIDADES
# --------------------------
CODE_REGEX = re.compile(r'^[A-Z]{1,4}-[A-Z0-9]{2,8}$')

def limpiar_texto(t):
    return re.sub(r'\s+', ' ', (t or "").strip())

def detectar_codigo_token(token_text):
    t = re.sub(r'[^A-Z0-9\-]', '', (token_text or "").upper())
    return t if CODE_REGEX.match(t) else None

def pil_from_pdfplumber_image(imobj):
    """Recibe page.to_image(...).original y devuelve PIL RGB"""
    pil = imobj
    if isinstance(imobj, dict) and "original" in imobj:  # si le pasa el dict .to_image() result
        pil = imobj["original"]
    if isinstance(pil, Image.Image):
        if pil.mode != "RGB":
            return pil.convert("RGB")
        return pil
    return Image.fromarray(pil)

# --------------------------
# DETECCIÓN DE REGIONES TIPO FOTO
# --------------------------
def detectar_regiones_fotograficas(page_image_bgr):
    """
    page_image_bgr: imagen OpenCV (BGR)
    Devuelve lista de rects (x,y,w,h)
    """
    img = page_image_bgr.copy()
    h, w = img.shape[:2]

    # 1. Escala (si página muy grande, considerar reescalar)
    # (mantengo tamaño nativo para coord con pdfplumber a escala DPI)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # 2. Blur + Canny
    blurred = cv2.GaussianBlur(gray, (5,5), 0)
    edges = cv2.Canny(blurred, EDGE_THRESHOLD_LOW, EDGE_THRESHOLD_HIGH)

    # 3. Dilate para unir bordes
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7,7))
    closed = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel, iterations=2)
    closed = cv2.dilate(closed, kernel, iterations=1)

    # 4. Contornos
    contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    rects = []
    for cnt in contours:
        x,y,wc,hc = cv2.boundingRect(cnt)
        area = wc*hc
        if area < MIN_AREA or area > MAX_AREA:
            continue
        ratio = wc / (hc + 1e-9)
        if ratio < ASPECT_RATIO_RANGE[0] or ratio > ASPECT_RATIO_RANGE[1]:
            continue
        # Evitar encabezados/márgenes: si está muy cerca del top y muy ancho, saltar
        if y < h*0.05 and wc > w*0.7:
            continue
        rects.append((x,y,wc,hc))

    # ordenar top->down, left->right
    rects = sorted(rects, key=lambda r: (r[1], r[0]))
    return rects

# NEW: intentar partir regiones que contengan dos productos apilados verticalmente
def split_region_by_horizontal_seam(page_image_bgr, rect,
                                    min_gap_px=8,
                                    min_gap_ratio=0.02,
                                    seam_thresh_factor=0.25,
                                    side_nonzero_ratio=0.25):
    """
    Intenta partir rect (x,y,w,h) en dos por una banda horizontal con pocos bordes.
    Devuelve lista de 1 o 2 rects en coordenadas de página.
    Parámetros conservadores por defecto (ajustables).
    """
    x,y,w,h = rect
    if h < 80:
        return [rect]

    crop = page_image_bgr[y:y+h, x:x+w]
    gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5,5), 0)
    edges = cv2.Canny(blurred, EDGE_THRESHOLD_LOW, EDGE_THRESHOLD_HIGH)

    # proyección horizontal (suma por filas) y suavizado
    horiz = np.sum(edges, axis=1).astype(np.float32)
    k = max(3, int(h * 0.01))
    kernel = np.ones(k) / k
    horiz_smooth = np.convolve(horiz, kernel, mode='same')

    med = np.median(horiz_smooth) + 1e-9
    thresh = med * seam_thresh_factor
    low = horiz_smooth < thresh

    # buscar segmentos contiguos bajos
    segments = []
    i = 0
    H = len(low)
    while i < H:
        if low[i]:
            j = i
            while j < H and low[j]:
                j += 1
            segments.append((i, j))
            i = j
        else:
            i += 1

    if not segments:
        return [rect]

    cy = h // 2
    total_nonzero = np.count_nonzero(edges)
    for a,b in segments:
        seg_h = b - a
        # debe cruzar el centro vertical del recorte y tener un tamaño mínimo relativo/absoluto
        if not (a < cy < b):
            continue
        if seg_h < max(min_gap_px, int(h * min_gap_ratio)):
            continue
        # verificar que la banda es relativamente "vacía" y lados con contenido
        seam_mean = horiz_smooth[a:b].mean()
        top_nonzero = np.count_nonzero(edges[:a, :])
        bot_nonzero = np.count_nonzero(edges[b:, :])
        if total_nonzero <= 0:
            continue
        if seam_mean < med * seam_thresh_factor and top_nonzero > total_nonzero * side_nonzero_ratio and bot_nonzero > total_nonzero * side_nonzero_ratio:
            split_y = y + (a + b) // 2
            top_rect = (x, y, w, split_y - y)
            bottom_rect = (x, split_y, w, y + h - split_y)
            return [top_rect, bottom_rect]

    return [rect]

# --------------------------
# DETECTAR CÓDIGOS EN LA PÁGINA (PDF text layer)
# --------------------------
def detectar_codigos_pdf(page):
    """
    Usa page.extract_words() para encontrar tokens que coincidan con CODE_REGEX.
    Devuelve lista de dicts con {token, cx, cy, x0, x1, top, bottom}
    coordenadas en pts (PDF coords). 
    También devolvemos centro en pixeles (multiplicado por scale al asociar).
    """
    words = page.extract_words()
    results = []
    for w in words:
        txt = limpiar_texto(w.get("text", ""))
        if not txt:
            continue
        code = detectar_codigo_token(txt)
        if code:
            # pdfplumber coords: x0,x1,top,bottom (origin top-left, y increases down)
            results.append({
                "token": code,
                "x0": float(w.get("x0",0)),
                "x1": float(w.get("x1",0)),
                "top": float(w.get("top",0)),
                "bottom": float(w.get("bottom",0)),
                "cx": (float(w.get("x0",0))+float(w.get("x1",0)))/2.0,
                "cy": (float(w.get("top",0))+float(w.get("bottom",0)))/2.0
            })
    return results

# --------------------------
# ASOCIAR RECTANGULOS DETECTADOS CON CÓDIGOS
# --------------------------
def asociar_regiones_a_codigos(regiones, codes, page_im_scale):
    """
    regiones: list of (x,y,w,h) en pixeles (imagen render)
    codes: lista de dicts con coords en pts (PDF coords)
    page_im_scale: factor scale (im.scale) para convertir pdf pts -> pixeles
    Devuelve mapping: region_index -> codigo_o_None
    """
    mapping = {}
    # preparar lista de códigos con coords en pixeles
    codes_px = []
    for c in codes:
        cx_px = c["cx"] * page_im_scale
        cy_px = c["cy"] * page_im_scale
        codes_px.append({**c, "cx_px": cx_px, "cy_px": cy_px})
    # para cada region calcular centro y buscar codigo mas cercano
    for i, (x,y,w,h) in enumerate(regiones):
        rcx = x + w/2.0
        rcy = y + h/2.0
        best = None
        best_dist = 1e9
        for c in codes_px:
            dx = abs(c["cx_px"] - rcx)
            dy = abs(c["cy_px"] - rcy)
            dist = math.hypot(dx, dy)
            if dist < best_dist:
                best_dist = dist
                best = c
        # aplicar thresholds dx/dy para asociar (evitar asociaciones débiles)
        if best is not None and abs(best["cx_px"] - rcx) <= ASSOC_MAX_DX and abs(best["cy_px"] - rcy) <= ASSOC_MAX_DY:
            mapping[i] = best["token"]
        else:
            mapping[i] = None
    return mapping

# --------------------------
# FUNCIONES DE GUARDADO
# --------------------------
def guardar_recorte(page_image_bgr, rect, out_path):
    x,y,w,h = rect
    rec = page_image_bgr[y:y+h, x:x+w]
    cv2.imwrite(out_path, rec)
    return out_path

def dibujar_debug(page_image_bgr, regiones, mapping, codes, page_idx):
    dbg = page_image_bgr.copy()
    # dibujar códigos
    for c in codes:
        # c coords are in PDF pts, need to convert to pixels externally (caller provides scale)
        pass
    # regiones
    for i, (x,y,w,h) in enumerate(regiones):
        cv2.rectangle(dbg, (x,y), (x+w, y+h), (0,0,255), 2)
        label = f"{i+1}"
        if mapping.get(i):
            label += f"->{mapping[i]}"
        cv2.putText(dbg, label, (x, max(y-6,5)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0),2)
    outp = os.path.join(DEBUG_DIR, f"page_{page_idx+1:02d}_regions_debug.png")
    cv2.imwrite(outp, dbg)
    return outp

# --------------------------
# MAIN: procesar PDF completo
# --------------------------
def procesar_pdf(pdf_path):
    with pdfplumber.open(pdf_path) as pdf:
        total_pages = len(pdf.pages)
        print(f"Procesando {total_pages} páginas de {pdf_path}")

        total_saved = 0
        for page_idx, page in enumerate(pdf.pages):
            print(f"\n--- Página {page_idx+1}/{total_pages} ---")
            # rasterizar página
            page_img_obj = page.to_image(resolution=DPI)
            # page_img_obj has attributes .original (PIL) and .scale etc.
            pil = page_img_obj.original
            page_bgr = cv2.cvtColor(np.array(pil), cv2.COLOR_RGB2BGR)
            scale = page_img_obj.scale  # factor pts -> pixels

            # 1) detectar regiones candidatas
            regiones = detectar_regiones_fotograficas(page_bgr)
            print(f"Detectadas {len(regiones)} regiones candidatas (página {page_idx+1})")

            # intentar partir regiones que parecen contener 2 productos verticalmente concatenados
            refined = []
            for r in regiones:
                splits = split_region_by_horizontal_seam(page_bgr, r)
                for s in splits:
                    refined.append(s)
            regiones = sorted(refined, key=lambda r: (r[1], r[0]))
            print(f"Regiones tras intento de split vertical: {len(regiones)}")

            # 2) detectar codigos en texto
            codes = detectar_codigos_pdf(page)
            print(f"Detectados {len(codes)} códigos en texto")

            # 3) asociar regiones a códigos
            mapping = {}
            if codes:
                mapping = asociar_regiones_a_codigos(regiones, codes, scale)
            else:
                mapping = {i: None for i in range(len(regiones))}

            # 4) guardar recortes; nombrado preferente por codigo si hay asociación
            for i, rect in enumerate(regiones):
                code = mapping.get(i)
                if code:
                    outname = f"{code}.jpg"
                else:
                    outname = f"page_{page_idx+1:02d}_img_{i+1:02d}.png"
                outpath = os.path.join(OUTPUT_DIR, outname)
                guardar_recorte(page_bgr, rect, outpath)
                print(f"Guardado: {outpath}  (assoc: {code})")
                total_saved += 1

            # 5) debug visual: dibujar rects y etiquetas
            dbg_path = dibujar_debug(page_bgr, regiones, mapping, codes, page_idx)
            print(f"Debug guardado: {dbg_path}")

        print(f"\n✅ Extracción completada: {total_saved} recortes guardados en '{OUTPUT_DIR}/'")

# --------------------------
# RUN
# --------------------------
if __name__ == "__main__":
    procesar_pdf(PDF_FILE)
